# backend/app/ai/model.py
def generate_response(prompt: str) -> str:
    """
    Returns a placeholder response.
    Replace this with your real LLM or API call (Gemini, OpenAI, etc.).
    """
    # Simple echo response for testing
    return f"[AI Reply] I received your message:\n{prompt}"
